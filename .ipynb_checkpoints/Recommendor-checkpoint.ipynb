{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6c0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4265f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the JSON data into Python\n",
    "with open('News_Category_Dataset_v3.json') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "# Flatten the JSON data into a tabular format using pandas\n",
    "df_list = []\n",
    "for d in data:\n",
    "    json_data = json.loads(d)\n",
    "    df = pd.json_normalize(json_data)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate the tabular data into a single DataFrame\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Export the tabular data to a CSV file\n",
    "df.to_csv('data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d88b3a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>23-09-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>23-09-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>23-09-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>23-09-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>22-09-2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "         date  \n",
       "0  23-09-2022  \n",
       "1  23-09-2022  \n",
       "2  23-09-2022  \n",
       "3  23-09-2022  \n",
       "4  22-09-2022  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b2de9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   short_description\n",
       "0  Health experts said it is too early to predict...\n",
       "1  He was subdued by passengers and crew when he ...\n",
       "2  \"Until you have a dog you don't understand wha...\n",
       "3  \"Accidentally put grown-up toothpaste on my to...\n",
       "4  Amy Cooper accused investment firm Franklin Te..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description=data[[\"short_description\"]]\n",
    "description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75983f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert input to string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Clean the text\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "067cbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#description_clean=description.apply(clean_text)\n",
    "data[\"short_description_clean\"] = data[\"short_description\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12d6267e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    health experts said it is too early to predict...\n",
       "1    he was subdued by passengers and crew when he ...\n",
       "2    until you have a dog you dont understand what ...\n",
       "3    accidentally put grownup toothpaste on my todd...\n",
       "4    amy cooper accused investment firm franklin te...\n",
       "5    the yearold woman was seen working at the sout...\n",
       "6    whos that behind you an anchor for new yorks p...\n",
       "7    more than half a million people remained witho...\n",
       "8    in mija director isabel castro combined music ...\n",
       "9    white house officials say the crux of the pres...\n",
       "Name: short_description_clean, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_description_clean=data[\"short_description_clean\"]\n",
    "short_description_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93bef0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mandali/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Starting tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "053a2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=short_description_clean.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd50cedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [health, experts, said, it, is, too, early, to...\n",
       "1    [he, was, subdued, by, passengers, and, crew, ...\n",
       "2    [until, you, have, a, dog, you, dont, understa...\n",
       "3    [accidentally, put, grownup, toothpaste, on, m...\n",
       "4    [amy, cooper, accused, investment, firm, frank...\n",
       "Name: short_description_clean, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32e0238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mandali/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "894adece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Get the list of English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(tokens,stop_words):\n",
    "    # Remove stop words from the tokenized text\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    \n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a97e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "short_desc_filtered = tokens.apply(lambda x: remove_stop_words(x, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c76b701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [health, experts, said, early, predict, whethe...\n",
       "1    [subdued, passengers, crew, fled, back, aircra...\n",
       "2                [dog, dont, understand, could, eaten]\n",
       "3    [accidentally, put, grownup, toothpaste, toddl...\n",
       "4    [amy, cooper, accused, investment, firm, frank...\n",
       "5    [yearold, woman, seen, working, south, carolin...\n",
       "6    [whos, behind, anchor, new, yorks, pix, asked,...\n",
       "7    [half, million, people, remained, without, wat...\n",
       "8    [mija, director, isabel, castro, combined, mus...\n",
       "9    [white, house, officials, say, crux, president...\n",
       "Name: short_description_clean, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_desc_filtered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b42bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/mandali/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61b23156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/mandali/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b9bdd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define function to lemmatize tokens\n",
    "def lemmatize_tokens(tokens):\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Apply lemmatization to short_desc_filtered\n",
    "short_desc_processed = short_desc_filtered.apply(lambda x: lemmatize_tokens(x))\n",
    "\n",
    "# Add processed text as new column to data dataframe\n",
    "#data[\"short_description_processed\"] = short_desc_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b054b9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [health, expert, said, early, predict, whether...\n",
       "1    [subdued, passenger, crew, fled, back, aircraf...\n",
       "2                [dog, dont, understand, could, eaten]\n",
       "3    [accidentally, put, grownup, toothpaste, toddl...\n",
       "4    [amy, cooper, accused, investment, firm, frank...\n",
       "5    [yearold, woman, seen, working, south, carolin...\n",
       "6    [who, behind, anchor, new, york, pix, asked, j...\n",
       "7    [half, million, people, remained, without, wat...\n",
       "8    [mija, director, isabel, castro, combined, mus...\n",
       "9    [white, house, official, say, crux, president,...\n",
       "Name: short_description_clean, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_desc_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ef321c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"short_description_processed\"] = short_desc_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca24f722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of short description vectors: (209527, 82124)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the processed short descriptions\n",
    "short_desc_vectors = vectorizer.fit_transform(data[\"short_description_processed\"].astype(str))\n",
    "\n",
    "# Convert the sparse matrix to a dense matrix\n",
    "short_desc_vectors_dense = short_desc_vectors.todense()\n",
    "\n",
    "# Print the shape of the dense matrix\n",
    "print(\"Shape of short description vectors:\", short_desc_vectors_dense.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f820784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c797c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
