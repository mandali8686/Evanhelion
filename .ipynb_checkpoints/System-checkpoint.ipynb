{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "  Downloading ktrain-0.34.0.tar.gz (25.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.3 MB 408 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from ktrain) (1.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from ktrain) (3.5.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from ktrain) (1.4.2)\n",
      "Collecting fastprogress>=0.1.21\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from ktrain) (2.27.1)\n",
      "Requirement already satisfied: joblib in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from ktrain) (1.1.0)\n",
      "Requirement already satisfied: packaging in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from ktrain) (21.3)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 266 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.2 MB 781 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cchardet\n",
      "  Downloading cchardet-2.1.7-cp39-cp39-macosx_10_9_x86_64.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 394 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from ktrain) (4.0.0)\n",
      "Collecting syntok>1.3.3\n",
      "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
      "Collecting tika\n",
      "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
      "Collecting transformers>=4.17.0\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 189 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 320 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras_bert>=0.86.0\n",
      "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
      "Collecting whoosh\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[K     |████████████████████████████████| 468 kB 251 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from keras_bert>=0.86.0->ktrain) (1.21.5)\n",
      "Collecting keras-transformer==0.40.0\n",
      "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
      "Collecting keras-pos-embd==0.13.0\n",
      "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
      "Collecting keras-multi-head==0.29.0\n",
      "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
      "Collecting keras-layer-normalization==0.16.0\n",
      "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
      "Collecting keras-position-wise-feed-forward==0.8.0\n",
      "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
      "Collecting keras-embed-sim==0.10.0\n",
      "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
      "Collecting keras-self-attention==0.51.0\n",
      "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->ktrain) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.1->ktrain) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->ktrain) (1.16.0)\n",
      "Requirement already satisfied: regex>2016 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from syntok>1.3.3->ktrain) (2022.3.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from transformers>=4.17.0->ktrain) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from transformers>=4.17.0->ktrain) (4.64.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 136 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-macosx_10_11_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 367 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.17.0->ktrain) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from requests->ktrain) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from requests->ktrain) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from requests->ktrain) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from requests->ktrain) (2.0.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->ktrain) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->ktrain) (2.2.0)\n",
      "Requirement already satisfied: setuptools in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tika->ktrain) (61.2.0)\n",
      "Building wheels for collected packages: ktrain, keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, jieba, langdetect, tika\n",
      "  Building wheel for ktrain (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ktrain: filename=ktrain-0.34.0-py3-none-any.whl size=25314863 sha256=09acfd216e12a4263b3956c3a02458a4aea672e6676c15f7c9e6023adc6d97ae\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/bd/76/14/8295b3e0dbe6203199daea7c583f520778edb66844d6d5f901\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33517 sha256=805bdd0bfb0868ffadfb447af8e444da08c595b2f3775e050c45a472ceb508ec\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/4e/26/24/14ecbc0166364db7f5500164b7d796263cf3cd10c57e892180\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12305 sha256=b5e7a00ab9ee8941482a2a7f0be387a2074fa370aaa9f635ae33f5f12bcc43c5\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/5e/d6/d1/c588c3b2b112c8f1173934995836ab2f2de8323cce99fa998f\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3960 sha256=781b0aafddedcc31af95b6439366f22fef910019004ea1b3632b315638181c70\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/cb/25/02/4bb438785ef9c10d07f6b3519f080b38917153fdac3108d738\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4668 sha256=4634711d55b2233c38a56d970df01a18b8f4c7a99bbce781aebf42c882beda2f\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/c1/df/15/a88cdf68ce687574649f65063a743123e1bee79932b6eea3b6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14993 sha256=bc91fb33bc629b44e54d76c7b93e3bec6c3558603b076bdbc00bfea6485ba3ff\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/b3/85/50/f232cac81ed1eb4dc20db31a9d1f4a8a1a8c696d4d27bff442\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6962 sha256=b0465f2cc09bb74abb5f8805bbebd463c94ca99dc600d47b9a6bd6972a0a9476\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/f5/8c/9a/917bf72d493e084ca1706a02679185789c2715f50770d8c987\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=07fb0e3e72a1dda2099759b8141fc55a0af46b9b5f48e6bbe3dadc8564dfd219\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/20/36/25/efb605ab1742a179274a6f7cb113da1c6758f45e212b59bb4d\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=749edbc3f21e2bf4e3b889b1301c4ee2d102ec89979a1cbadcb0aa283c9c090d\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/78/c1/84/b83a2fd6f1d63e136cba74bac4126bee3b8705eef6486635fd\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=476151ebf2a5fb20d79c72e4c7865430724ec7bcdd4a3db29937e5b0ce5d77a9\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/7d/74/cf/08c94db4b784e2c1ef675a600b7b5b281fd25240dcb954ee7e\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=ba61a8203b6a7cd622751cd6efb2d53fd4ab4879db9046078b11ad6871def566\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "  Building wheel for tika (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32642 sha256=8cee85996b7a0f52a08a73641741db738039f1a53b11a01653153515942b6a03\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/13/56/18/e752060632d32c39c9c4545e756dad281f8504dafcfac02b95\n",
      "Successfully built ktrain keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention jieba langdetect tika\n",
      "Installing collected packages: keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, tokenizers, keras-transformer, huggingface-hub, whoosh, transformers, tika, syntok, sentencepiece, langdetect, keras-bert, jieba, fastprogress, cchardet, ktrain\n",
      "Successfully installed cchardet-2.1.7 fastprogress-1.0.3 huggingface-hub-0.13.3 jieba-0.42.1 keras-bert-0.89.0 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 ktrain-0.34.0 langdetect-1.0.9 sentencepiece-0.1.97 syntok-1.4.4 tika-2.6.0 tokenizers-0.13.2 transformers-4.27.4 whoosh-2.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp39-cp39-macosx_10_15_x86_64.whl (230.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 230.1 MB 70 kB/s  eta 0:00:01     |█████████████████████▋          | 155.6 MB 483 kB/s eta 0:02:35\n",
      "\u001b[?25hRequirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: packaging in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/gast/\u001b[0m\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.1.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-macosx_10_9_x86_64.whl (26.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.7 MB 688 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[K     |████████████████████████████████| 440 kB 832 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp39-cp39-macosx_10_14_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 225 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: setuptools in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (61.2.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.23.5-cp39-cp39-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 18.1 MB 505 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.22.1-cp37-abi3-macosx_10_9_universal2.whl (397 kB)\n",
      "\u001b[K     |████████████████████████████████| 397 kB 260 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 220 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 441 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jax>=0.3.15\n",
      "  Downloading jax-0.4.8.tar.gz (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 638 kB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting ml-dtypes>=0.0.3\n",
      "  Downloading ml_dtypes-0.0.4-cp39-cp39-macosx_10_9_universal2.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 289 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.7 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (1.7.3)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.22.4-cp39-cp39-macosx_10_15_x86_64.whl (17.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.7 MB 276 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.33.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 404 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.0.3)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.53.0-cp39-cp39-macosx_10_10_universal2.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 290 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.2.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.9)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/mandali/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.8-py3-none-any.whl size=1439678 sha256=a58accc0cfad4e5f745f9d270effb0a4fd336c19152901fe06e54f22c80af00f\n",
      "  Stored in directory: /Users/mandali/Library/Caches/pip/wheels/05/94/dc/81042da9bced43ff430bc02043d213d9e4b210b584c39e31c1\n",
      "Successfully built jax\n",
      "Installing collected packages: oauthlib, requests-oauthlib, numpy, tensorboard-plugin-wit, tensorboard-data-server, protobuf, opt-einsum, ml-dtypes, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, libclang, keras, jax, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.22.4 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.3.3 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.53.0 jax-0.4.8 keras-2.12.0 libclang-16.0.0 ml-dtypes-0.0.4 numpy-1.22.4 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.22.1 requests-oauthlib-1.3.1 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0 termcolor-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import ktrain\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ('headers', 'footers', 'quotes')\n",
    "train = fetch_20newsgroups(subset='train', remove=remove)\n",
    "test = fetch_20newsgroups(subset='test', remove=remove)\n",
    "\n",
    "texts = train.data + test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_topics automatically set to 97\n",
      "lang: en\n",
      "preprocessing texts...\n",
      "fitting model...\n",
      "iteration: 1 of max_iter: 5\n",
      "iteration: 2 of max_iter: 5\n",
      "iteration: 3 of max_iter: 5\n",
      "iteration: 4 of max_iter: 5\n",
      "iteration: 5 of max_iter: 5\n",
      "done.\n",
      "CPU times: user 9min 2s, sys: 1min 54s, total: 10min 57s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tm = ktrain.text.get_topic_model(texts, n_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "tm.build(texts, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.train_recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtext=\"\"\" New York\n",
    "CNN\n",
    " — \n",
    "News organizations have a message for Elon Musk: We are not going to pay you for checkmarks on Twitter.\n",
    "\n",
    "The New York Times, Los Angeles Times, the Washington Post, BuzzFeed, POLITICO, and Vox all scoffed at the notion on Thursday that they would pay Twitter for the feature, which has been free since it was introduced years ago but will soon be phased out.\n",
    "\n",
    "CNN said it has no intention of paying for Twitter’s subscription service for its accounts but would make a few exceptions for some key staff.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(tm.recommend(text=rawtext, n=5)):\n",
    "    print('Result #%s'%(i+1))\n",
    "    print(\"Text \\n\")\n",
    "    print(\" \".join(doc['text'].split()[:500]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
